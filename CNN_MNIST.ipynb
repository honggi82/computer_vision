{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_MNIST.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNqA+ofoC1MAwlaSSW+L26h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/honggi82/computer_vision/blob/main/CNN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpSzISkFc0xk",
        "outputId": "4b6a4256-b323-4a84-d8e8-c75a7b0e631f"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, pooling, Flatten, Dense\n",
        "\n",
        "# MNIST data\n",
        "(train_X, train_Y), (test_X, test_Y) = mnist.load_data()\n",
        "\n",
        "print(train_X.shape,  train_Y.shape,  test_X.shape,  test_Y.shape)\n",
        "\n",
        "train_X = train_X.reshape(train_X.shape[0], 28,28,1).astype('float32')/255.0\n",
        "test_X = test_X.reshape(test_X.shape[0], 28,28,1).astype('float32')/255.0\n",
        "\n",
        "train_Y = np_utils.to_categorical(train_Y) # One-Hot Encoding\n",
        "test_Y = np_utils.to_categorical(test_Y) # One-Hot Encoding\n",
        "\n",
        "# Model\n",
        "model = Sequential([\n",
        "Conv2D(32, (3,3), padding='same', strides=(1,1), activation='relu', input_shape=(28,28,1)),\n",
        "pooling.MaxPooling2D(pool_size=(2,2)),\n",
        "Conv2D(64, (3,3), padding='same', strides=(1,1), activation='relu'),\n",
        "pooling.MaxPooling2D(pool_size=(2,2)),\n",
        "Flatten(),\n",
        "Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Training\n",
        "model.fit(train_X, train_Y, epochs=25)\n",
        "# Testing\n",
        "_, accuracy = model.evaluate(test_X, test_Y)\n",
        "print('Accuracy: ', accuracy)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                31370     \n",
            "=================================================================\n",
            "Total params: 50,186\n",
            "Trainable params: 50,186\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "1875/1875 [==============================] - 64s 34ms/step - loss: 0.5168 - accuracy: 0.8522\n",
            "Epoch 2/25\n",
            "1875/1875 [==============================] - 63s 34ms/step - loss: 0.1688 - accuracy: 0.9505\n",
            "Epoch 3/25\n",
            "1875/1875 [==============================] - 64s 34ms/step - loss: 0.1150 - accuracy: 0.9667\n",
            "Epoch 4/25\n",
            "1875/1875 [==============================] - 64s 34ms/step - loss: 0.0917 - accuracy: 0.9726\n",
            "Epoch 5/25\n",
            "1875/1875 [==============================] - 65s 35ms/step - loss: 0.0783 - accuracy: 0.9768\n",
            "Epoch 6/25\n",
            "1875/1875 [==============================] - 65s 35ms/step - loss: 0.0696 - accuracy: 0.9792\n",
            "Epoch 7/25\n",
            "1875/1875 [==============================] - 65s 35ms/step - loss: 0.0625 - accuracy: 0.9811\n",
            "Epoch 8/25\n",
            "1875/1875 [==============================] - 66s 35ms/step - loss: 0.0577 - accuracy: 0.9824\n",
            "Epoch 9/25\n",
            "1875/1875 [==============================] - 68s 36ms/step - loss: 0.0540 - accuracy: 0.9837\n",
            "Epoch 10/25\n",
            "1875/1875 [==============================] - 66s 35ms/step - loss: 0.0508 - accuracy: 0.9839\n",
            "Epoch 11/25\n",
            "1875/1875 [==============================] - 66s 35ms/step - loss: 0.0488 - accuracy: 0.9852\n",
            "Epoch 12/25\n",
            "1875/1875 [==============================] - 65s 35ms/step - loss: 0.0466 - accuracy: 0.9855\n",
            "Epoch 13/25\n",
            "1875/1875 [==============================] - 66s 35ms/step - loss: 0.0443 - accuracy: 0.9862\n",
            "Epoch 14/25\n",
            "1875/1875 [==============================] - 65s 35ms/step - loss: 0.0421 - accuracy: 0.9867\n",
            "Epoch 15/25\n",
            "1875/1875 [==============================] - 66s 35ms/step - loss: 0.0409 - accuracy: 0.9877\n",
            "Epoch 16/25\n",
            "1875/1875 [==============================] - 66s 35ms/step - loss: 0.0392 - accuracy: 0.9880\n",
            "Epoch 17/25\n",
            "1875/1875 [==============================] - 66s 35ms/step - loss: 0.0383 - accuracy: 0.9882\n",
            "Epoch 18/25\n",
            "1875/1875 [==============================] - 66s 35ms/step - loss: 0.0362 - accuracy: 0.9890\n",
            "Epoch 19/25\n",
            "1875/1875 [==============================] - 66s 35ms/step - loss: 0.0359 - accuracy: 0.9889\n",
            "Epoch 20/25\n",
            "1875/1875 [==============================] - 66s 35ms/step - loss: 0.0344 - accuracy: 0.9893\n",
            "Epoch 21/25\n",
            "1875/1875 [==============================] - 66s 35ms/step - loss: 0.0333 - accuracy: 0.9899\n",
            "Epoch 22/25\n",
            "1875/1875 [==============================] - 66s 35ms/step - loss: 0.0321 - accuracy: 0.9900\n",
            "Epoch 23/25\n",
            "1875/1875 [==============================] - 66s 35ms/step - loss: 0.0310 - accuracy: 0.9906\n",
            "Epoch 24/25\n",
            "1875/1875 [==============================] - 66s 35ms/step - loss: 0.0299 - accuracy: 0.9906\n",
            "Epoch 25/25\n",
            "1875/1875 [==============================] - 66s 35ms/step - loss: 0.0290 - accuracy: 0.9912\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0430 - accuracy: 0.9855\n",
            "Accuracy:  0.9854999780654907\n"
          ]
        }
      ]
    }
  ]
}