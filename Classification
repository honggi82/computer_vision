import numpy as np
import matplotlib.pyplot as plt

n = 50; # data number

a = np.array([np.random.rand(n)+1, np.random.rand(n)+1])
b = np.array([np.random.rand(n)+2, np.random.rand(n)+2])
X = np.concatenate((a,b), axis=1)

plt.scatter(X[0,:n], X[1, :n], c='r', marker=".")
plt.scatter(X[0, n+1:2*n], X[1, n+1:2*n], c='b', marker=".")
plt.show()

lr = 0.01; # learning rate
T = 0.5; # threshold
hist_E=[]; # history of error
err = 100; # initialization of values

y=np.concatenate((np.ones(n), -1*np.ones(n)),axis=0)
X=np.concatenate(([np.ones(n*2)],X), axis=0)
w = np.random.rand(X.shape[0])

# Gradient descent
while err>0.1:
    # prediction
    p = np.dot(w,X)
    out = np.where(p > T,1,-1)
    # trainning
    cost=np.tile((out-y), (3,1))*X
    w = w - (lr/n)*cost.sum(axis=1)
    err=(1/2*n)*np.sum((out-y)*(out-y))
    hist_E.append(err)

plt.plot(hist_E)
