{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_CIFAR.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/honggi82/computer_vision/blob/main/CNN_CIFAR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U5in5DMdf2E",
        "outputId": "32c34440-0ddf-41d8-b085-9a7a3979b460"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
        "\n",
        "# MNIST data\n",
        "(train_X, train_Y), (test_X, test_Y) = cifar10.load_data()\n",
        "print(train_X.shape, train_Y.shape, test_X.shape, test_Y.shape)\n",
        "\n",
        "train_X = train_X.astype('float32')/255.0\n",
        "test_X = test_X.astype('float32')/255.0\n",
        "\n",
        "train_Y = to_categorical(train_Y) # One-Hot Encoding\n",
        "test_Y = to_categorical(test_Y) # One-Hot Encoding\n",
        "\n",
        "# Model\n",
        "model = Sequential([\n",
        "Conv2D(32, (3,3), padding='same', strides=(1,1), activation='relu', input_shape=(32,32,3)),\n",
        "MaxPooling2D(pool_size=(2,2)),\n",
        "Conv2D(64, (3,3), padding='same', strides=(1,1), activation='relu'),\n",
        "MaxPooling2D(pool_size=(2,2)),\n",
        "Conv2D(64, (3,3), padding='same', strides=(1,1), activation='relu'),\n",
        "MaxPooling2D(pool_size=(2,2)),\n",
        "Flatten(),\n",
        "Dropout(0.5),\n",
        "Dense(10, activation='softmax')]) # units=10, activation='softmax'\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Training\n",
        "model.fit(train_X, train_Y, batch_size=8,epochs=50)\n",
        "# Testing\n",
        "_, accuracy = model.evaluate(test_X, test_Y)\n",
        "print('Accuracy: ', accuracy)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66570 (260.04 KB)\n",
            "Trainable params: 66570 (260.04 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "6250/6250 [==============================] - 32s 4ms/step - loss: 1.4907 - accuracy: 0.4612\n",
            "Epoch 2/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 1.1636 - accuracy: 0.5885\n",
            "Epoch 3/50\n",
            "6250/6250 [==============================] - 26s 4ms/step - loss: 1.0524 - accuracy: 0.6293\n",
            "Epoch 4/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.9946 - accuracy: 0.6502\n",
            "Epoch 5/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.9560 - accuracy: 0.6646\n",
            "Epoch 6/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.9215 - accuracy: 0.6763\n",
            "Epoch 7/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.8970 - accuracy: 0.6870\n",
            "Epoch 8/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.8715 - accuracy: 0.6972\n",
            "Epoch 9/50\n",
            "6250/6250 [==============================] - 24s 4ms/step - loss: 0.8637 - accuracy: 0.6975\n",
            "Epoch 10/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.8489 - accuracy: 0.7043\n",
            "Epoch 11/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.8343 - accuracy: 0.7077\n",
            "Epoch 12/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.8243 - accuracy: 0.7107\n",
            "Epoch 13/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.8175 - accuracy: 0.7117\n",
            "Epoch 14/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.8033 - accuracy: 0.7186\n",
            "Epoch 15/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.8043 - accuracy: 0.7170\n",
            "Epoch 16/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.7977 - accuracy: 0.7196\n",
            "Epoch 17/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.7795 - accuracy: 0.7254\n",
            "Epoch 18/50\n",
            "6250/6250 [==============================] - 24s 4ms/step - loss: 0.7785 - accuracy: 0.7273\n",
            "Epoch 19/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.7761 - accuracy: 0.7302\n",
            "Epoch 20/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.7659 - accuracy: 0.7314\n",
            "Epoch 21/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.7615 - accuracy: 0.7333\n",
            "Epoch 22/50\n",
            "6250/6250 [==============================] - 26s 4ms/step - loss: 0.7562 - accuracy: 0.7370\n",
            "Epoch 23/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.7524 - accuracy: 0.7384\n",
            "Epoch 24/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.7499 - accuracy: 0.7356\n",
            "Epoch 25/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.7432 - accuracy: 0.7425\n",
            "Epoch 26/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.7406 - accuracy: 0.7414\n",
            "Epoch 27/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.7426 - accuracy: 0.7393\n",
            "Epoch 28/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.7378 - accuracy: 0.7411\n",
            "Epoch 29/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.7277 - accuracy: 0.7443\n",
            "Epoch 30/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.7245 - accuracy: 0.7475\n",
            "Epoch 31/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.7227 - accuracy: 0.7481\n",
            "Epoch 32/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.7209 - accuracy: 0.7503\n",
            "Epoch 33/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.7192 - accuracy: 0.7486\n",
            "Epoch 34/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.7076 - accuracy: 0.7515\n",
            "Epoch 35/50\n",
            "6250/6250 [==============================] - 24s 4ms/step - loss: 0.7125 - accuracy: 0.7503\n",
            "Epoch 36/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.7090 - accuracy: 0.7546\n",
            "Epoch 37/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.7053 - accuracy: 0.7534\n",
            "Epoch 38/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.6977 - accuracy: 0.7569\n",
            "Epoch 39/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.6958 - accuracy: 0.7588\n",
            "Epoch 40/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.7019 - accuracy: 0.7536\n",
            "Epoch 41/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.6895 - accuracy: 0.7596\n",
            "Epoch 42/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.6919 - accuracy: 0.7578\n",
            "Epoch 43/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.6930 - accuracy: 0.7560\n",
            "Epoch 44/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.6921 - accuracy: 0.7561\n",
            "Epoch 45/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.6912 - accuracy: 0.7601\n",
            "Epoch 46/50\n",
            "6250/6250 [==============================] - 26s 4ms/step - loss: 0.6954 - accuracy: 0.7570\n",
            "Epoch 47/50\n",
            "6250/6250 [==============================] - 26s 4ms/step - loss: 0.6891 - accuracy: 0.7589\n",
            "Epoch 48/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.6862 - accuracy: 0.7610\n",
            "Epoch 49/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.6888 - accuracy: 0.7588\n",
            "Epoch 50/50\n",
            "6250/6250 [==============================] - 25s 4ms/step - loss: 0.6868 - accuracy: 0.7600\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.8465 - accuracy: 0.7201\n",
            "Accuracy:  0.7200999855995178\n"
          ]
        }
      ]
    }
  ]
}